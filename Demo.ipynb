{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8419041a",
   "metadata": {},
   "source": [
    "# Data Extraction (Text-to-KG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c372b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "\n",
    "'''\n",
    "You need the following environment variables:\n",
    "\n",
    "    1. NEO4J_URL (Default=\"bolt://localhost:7687\"), \n",
    "    2. NEO4J_USERNAME (Default=\"neo4j\"), \n",
    "    3. NEO4J_PASSWORD (Default=None), \n",
    "    4. NEO4J_DATABASE (Default=\"neo4j\")\n",
    "    (The above are for establishing a Neo4j Connection and can be passed as arguments as well)\n",
    "    5. MODELS_CACHE_FOLDER (Default=None):- \n",
    "        I'm using SentenceTransformer model \"all-MiniLM-v6-L2\" for creating embeddings to calculate vector similarity.\n",
    "        This is just the path to the folder to use as the cache folder\n",
    "    6. GOOGLE_API_KEY (For ChatGoogleGenerativeAI) or any other API key for env variable if you want to use some other LLM\n",
    "    7. TESSDATA_PREFIX (Might need it for using PyTesseract)\n",
    "'''\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from kgrag.data_extraction import Text2KG\n",
    "from kgrag.parse_pdf import PDFParserMarkdown, OCREngine\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "set_llm_cache(InMemoryCache()) # Set LLM Caching (Optional)\n",
    "\n",
    "# Replace with llm you want to use\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.0-pro\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03a70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = input(\"Please enter filepath of the file you want to process: \")\n",
    "# filepath = \"../SampleDocs/Leadership-Etsko-Schuitema.pdf\" # ...or any other file you want to use\n",
    "filepath = filepath = \"/media/wali/D_Drive/Documents/Books/C++_Programming_Program_Design_Including_Data_Structure_D.S.Malik_5th_DS.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df389ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Can also accept neo4j_url, neo4j_username, neo4j_password & neo4j_database arguments\n",
    "# if the above mentioned environment variables have not been set\n",
    "text2kg = Text2KG(\n",
    "    llm=llm,\n",
    "    emb_model=None, # By Default, SentenceTransformer is used ot use any other embedding model\n",
    "    disambiguate_nodes=False,\n",
    "    link_nodes=True,\n",
    "    node_vector_similarity_threshold=0.90,\n",
    "    subject=filepath.split('/')[-1].split('.')[0].replace('_',' ').replace('-',' '), # Subject can be anything or nothing - filename works well for most cases\n",
    "    verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse or read the PDF file\n",
    "Can use any parser as long as some conditions are observed in the output:\n",
    "    1. Must be in langchain_core.documents.base.Document format\n",
    "    2. Must contain the following keys in doc.metadata:\n",
    "        1. page\n",
    "        2. filename/filepath or source\n",
    "'''\n",
    "\n",
    "pages =  list(range(42, 44)) #list(range(68,70)) # None\n",
    "\n",
    "parser = PDFParserMarkdown(\n",
    "    pdf_path=filepath,\n",
    "    pages=pages, # Can pass a list of pages to read, useful for debugging\n",
    "    ocr_engine=OCREngine.PYTESSERACT, # 3 OCR Options: PYTESSERACT, LLM, RAPIDOCR (LLM is most accurate)\n",
    ") \n",
    "\n",
    "doc_dicts: List[Dict[str, Any]] = parser.process_pdf_document()\n",
    "\n",
    "docs: List[Document] = [\n",
    "    Document(\n",
    "        page_content=doc['text'],\n",
    "        metadata={**doc['page_metadata'], **doc['doc_metadata']}\n",
    "    )\n",
    "    for doc in doc_dicts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ce860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90717d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.process_time()\n",
    "text2kg.process_documents(docs)\n",
    "end_time = time.process_time()\n",
    "print(f\"Total Time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92634180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47bbeed",
   "metadata": {},
   "source": [
    "# KG Search / Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9544a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from kgrag.kg_search import KGSearch\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.0-pro\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kg_search = KGSearch(\n",
    "    ent_llm=llm,\n",
    "    cypher_llm=llm,\n",
    "    cypher_examples_json=\"examples.json\",\n",
    "    fulltext_search_top_k=5,\n",
    "    vector_search_top_k=5,\n",
    "    vector_search_min_score=0.8\n",
    ")\n",
    "\n",
    "query = input(\"Enter your query: \") # \"How does relation extraction work?\"\n",
    "\n",
    "docs_str = kg_search.retrieve_as_string(\n",
    "    query, \n",
    "    nresults=30,\n",
    "    use_fulltext_search=True, # Extract all entities (using ent_llm) in the input query and search using fulltext search\n",
    "    use_vector_search=True, # Search for all entities/nodes in the query using vector search\n",
    "    generate_cypher=False # Use LLM (cypher_llm) to generate cypher - Uses examples from `cypher_examples_json` for guidance\n",
    ")\n",
    "print(docs_str)\n",
    "'''\n",
    "OR get lists of strings separately using kg_search.retrieve - retrieve_as_string is only a wrapper for this function\n",
    "\n",
    "rels, docs, gen_cypher_results = kg_search.retrieve(\n",
    "    query, \n",
    "    nresults=30,\n",
    "    use_fulltext_search=True, \n",
    "    use_vector_search=True,\n",
    "    generate_cypher=False\n",
    ")\n",
    "rels: All the triples that the entities in the query are involved in \n",
    "     Empty list is returned if `use_fulltext_search=False` & `use_vector_search=False`\n",
    "docs: All the documents that contain any entities mentioned in the query\n",
    "     Empty list is returned if `use_fulltext_search=False` & `use_vector_search=False`\n",
    "gen_cypher_results: List of string/JSON results from the generated cypher\n",
    "     Empty list is returned if `generate_cypher=False`\n",
    "\n",
    "If no entities are found using vector or fulltext search, then a cypher is generated regardless of the value of `generate_cypher`\n",
    "And results are returned in the gen_cypher_results\n",
    "WARNING: Using `generate_cypher` is unreliable and error-prone. Needs more work and more examples from 'examples.json'\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgrag-py3.10",
   "language": "python",
   "name": "kgrag-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
